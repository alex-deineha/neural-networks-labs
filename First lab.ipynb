{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "D = [[],[]]\n",
    "T = []\n",
    "for i in np.arange(10)*0.1:\n",
    "    for j in np.arange(10)*0.1:\n",
    "        D[0].append(i)\n",
    "        D[1].append(j)\n",
    "        T.append(i*j+i*i-j*j)\n",
    "        \n",
    "D = np.array(D).T\n",
    "T = np.array(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "??Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_105 (Dense)            (None, 5)                 15        \n",
      "_________________________________________________________________\n",
      "activation_105 (Activation)  (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 1)                 6         \n",
      "_________________________________________________________________\n",
      "activation_106 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 21\n",
      "Trainable params: 21\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "model = Sequential([\n",
    "    Dense(5, input_shape=(2,)),\n",
    "    Activation('sigmoid'),\n",
    "    Dense(1),\n",
    "    Activation('linear'),\n",
    "])\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.1.\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 0.2280\n",
      "Epoch 2/50\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.095.\n",
      "100/100 [==============================] - 0s 107us/step - loss: 0.1302\n",
      "Epoch 3/50\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.09025.\n",
      "100/100 [==============================] - 0s 105us/step - loss: 0.1253\n",
      "Epoch 4/50\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.0857375.\n",
      "100/100 [==============================] - 0s 99us/step - loss: 0.0916\n",
      "Epoch 5/50\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.081450625.\n",
      "100/100 [==============================] - 0s 102us/step - loss: 0.0808\n",
      "Epoch 6/50\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.07737809374999999.\n",
      "100/100 [==============================] - 0s 100us/step - loss: 0.0502\n",
      "Epoch 7/50\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.07350918906249998.\n",
      "100/100 [==============================] - 0s 100us/step - loss: 0.0454\n",
      "Epoch 8/50\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.06983372960937498.\n",
      "100/100 [==============================] - 0s 92us/step - loss: 0.0237\n",
      "Epoch 9/50\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.06634204312890622.\n",
      "100/100 [==============================] - 0s 93us/step - loss: 0.0339\n",
      "Epoch 10/50\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.0630249409724609.\n",
      "100/100 [==============================] - 0s 102us/step - loss: 0.0232\n",
      "Epoch 11/50\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.05987369392383787.\n",
      "100/100 [==============================] - 0s 92us/step - loss: 0.0237\n",
      "Epoch 12/50\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.05688000922764597.\n",
      "100/100 [==============================] - 0s 97us/step - loss: 0.0235\n",
      "Epoch 13/50\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.05403600876626367.\n",
      "100/100 [==============================] - 0s 101us/step - loss: 0.0240\n",
      "Epoch 14/50\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.051334208327950485.\n",
      "100/100 [==============================] - 0s 97us/step - loss: 0.0201\n",
      "Epoch 15/50\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.04876749791155296.\n",
      "100/100 [==============================] - 0s 105us/step - loss: 0.0213\n",
      "Epoch 16/50\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.046329123015975304.\n",
      "100/100 [==============================] - 0s 94us/step - loss: 0.0210\n",
      "Epoch 17/50\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.04401266686517654.\n",
      "100/100 [==============================] - 0s 100us/step - loss: 0.0204\n",
      "Epoch 18/50\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.04181203352191771.\n",
      "100/100 [==============================] - 0s 93us/step - loss: 0.0191\n",
      "Epoch 19/50\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.039721431845821824.\n",
      "100/100 [==============================] - 0s 101us/step - loss: 0.0187\n",
      "Epoch 20/50\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.03773536025353073.\n",
      "100/100 [==============================] - 0s 98us/step - loss: 0.0195\n",
      "Epoch 21/50\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 0.03584859224085419.\n",
      "100/100 [==============================] - 0s 98us/step - loss: 0.0193\n",
      "Epoch 22/50\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 0.03405616262881148.\n",
      "100/100 [==============================] - 0s 111us/step - loss: 0.0185\n",
      "Epoch 23/50\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 0.0323533544973709.\n",
      "100/100 [==============================] - 0s 85us/step - loss: 0.0185\n",
      "Epoch 24/50\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 0.03073568677250236.\n",
      "100/100 [==============================] - 0s 106us/step - loss: 0.0185\n",
      "Epoch 25/50\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 0.02919890243387724.\n",
      "100/100 [==============================] - 0s 101us/step - loss: 0.0188\n",
      "Epoch 26/50\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 0.027738957312183378.\n",
      "100/100 [==============================] - 0s 103us/step - loss: 0.0186\n",
      "Epoch 27/50\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 0.026352009446574204.\n",
      "100/100 [==============================] - 0s 91us/step - loss: 0.0194\n",
      "Epoch 28/50\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 0.025034408974245494.\n",
      "100/100 [==============================] - 0s 98us/step - loss: 0.0185\n",
      "Epoch 29/50\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 0.023782688525533217.\n",
      "100/100 [==============================] - 0s 100us/step - loss: 0.0190\n",
      "Epoch 30/50\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 0.022593554099256556.\n",
      "100/100 [==============================] - 0s 87us/step - loss: 0.0195\n",
      "Epoch 31/50\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 0.02146387639429373.\n",
      "100/100 [==============================] - 0s 95us/step - loss: 0.0191\n",
      "Epoch 32/50\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 0.02039068257457904.\n",
      "100/100 [==============================] - 0s 92us/step - loss: 0.0184\n",
      "Epoch 33/50\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 0.019371148445850087.\n",
      "100/100 [==============================] - 0s 92us/step - loss: 0.0184\n",
      "Epoch 34/50\n",
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 0.018402591023557582.\n",
      "100/100 [==============================] - 0s 89us/step - loss: 0.0186\n",
      "Epoch 35/50\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 0.017482461472379703.\n",
      "100/100 [==============================] - 0s 91us/step - loss: 0.0182\n",
      "Epoch 36/50\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 0.016608338398760716.\n",
      "100/100 [==============================] - 0s 94us/step - loss: 0.0192\n",
      "Epoch 37/50\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 0.01577792147882268.\n",
      "100/100 [==============================] - 0s 92us/step - loss: 0.0204\n",
      "Epoch 38/50\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 0.014989025404881546.\n",
      "100/100 [==============================] - 0s 91us/step - loss: 0.0191\n",
      "Epoch 39/50\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 0.014239574134637467.\n",
      "100/100 [==============================] - 0s 84us/step - loss: 0.0186\n",
      "Epoch 40/50\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 0.013527595427905593.\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.0190\n",
      "Epoch 41/50\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 0.012851215656510312.\n",
      "100/100 [==============================] - 0s 83us/step - loss: 0.0187\n",
      "Epoch 42/50\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 0.012208654873684797.\n",
      "100/100 [==============================] - 0s 87us/step - loss: 0.0182\n",
      "Epoch 43/50\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 0.011598222130000557.\n",
      "100/100 [==============================] - 0s 81us/step - loss: 0.0183\n",
      "Epoch 44/50\n",
      "\n",
      "Epoch 00044: LearningRateScheduler setting learning rate to 0.011018311023500529.\n",
      "100/100 [==============================] - 0s 85us/step - loss: 0.0183\n",
      "Epoch 45/50\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 0.010467395472325502.\n",
      "100/100 [==============================] - 0s 89us/step - loss: 0.0181\n",
      "Epoch 46/50\n",
      "\n",
      "Epoch 00046: LearningRateScheduler setting learning rate to 0.009944025698709225.\n",
      "100/100 [==============================] - 0s 82us/step - loss: 0.0184\n",
      "Epoch 47/50\n",
      "\n",
      "Epoch 00047: LearningRateScheduler setting learning rate to 0.009446824413773765.\n",
      "100/100 [==============================] - 0s 83us/step - loss: 0.0183\n",
      "Epoch 48/50\n",
      "\n",
      "Epoch 00048: LearningRateScheduler setting learning rate to 0.008974483193085076.\n",
      "100/100 [==============================] - 0s 86us/step - loss: 0.0182\n",
      "Epoch 49/50\n",
      "\n",
      "Epoch 00049: LearningRateScheduler setting learning rate to 0.00852575903343082.\n",
      "100/100 [==============================] - 0s 83us/step - loss: 0.0181\n",
      "Epoch 50/50\n",
      "\n",
      "Epoch 00050: LearningRateScheduler setting learning rate to 0.00809947108175928.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32/100 [========>.....................] - ETA: 0s - loss: 0.0147\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "100/100 [==============================] - 0s 80us/step - loss: 0.0183\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import LearningRateScheduler\n",
    "def step_decay_schedule(initial_lr=1e-3, decay_factor=0.75, step_size=10):\n",
    "    '''\n",
    "    Wrapper function to create a LearningRateScheduler with step decay schedule.\n",
    "    '''\n",
    "    def schedule(epoch):\n",
    "        return initial_lr * (decay_factor ** np.floor(epoch/step_size))\n",
    "    return LearningRateScheduler(schedule, verbose=1)\n",
    "\n",
    "lr_sched = step_decay_schedule(initial_lr=1e-1, decay_factor=0.95, step_size=1)\n",
    "\n",
    "history = model.fit(D, T, callbacks=[lr_sched], epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history(history):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "#     # Plot training & validation accuracy values\n",
    "#     plt.plot(history.history['acc'])\n",
    "#     plt.plot(history.history['val_acc'])\n",
    "#     plt.title('Model accuracy')\n",
    "#     plt.ylabel('Accuracy')\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.legend(['Train', 'Test'], loc='upper left')\n",
    "#     plt.show()\n",
    "\n",
    "#     # Plot training & validation loss values\n",
    "#     plt.plot(history.history['loss'])\n",
    "#     plt.plot(history.history['val_loss'])\n",
    "#     plt.title('Model loss')\n",
    "#     plt.ylabel('Loss')\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.legend(['Train', 'Test'], loc='upper left')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.02239025816321373"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(D.T, T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
